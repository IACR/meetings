# June 2022 Virtual Meeting

The Private Advertising Technology Community Group's meeting will be meeting two days for 3 hours at the same time both days.

## Schedule 

### Day 1 Start 

| Time          | Day    | Location      |
| ------------- | ------ | ------------- |
| 15:00 (03 PM) | 21 Tue | Tokyo         |
| 16:00 (04 PM) | 21 Tue | Sydney        |
| 23:00 (11 PM) | 20 Mon | Seattle       |
| 02:00         | 21 Tue | Boston        |
| 07:00         | 21 Tue | London        |
| 08:00         | 21 Tue | Brussels      |

### Day 2 Start 

| Time          | Day    | Location      |
| ------------- | ------ | ------------- |
| 15:00 (03 PM) | 21 Thu | Tokyo         |
| 16:00 (04 PM) | 21 Thu | Sydney        |
| 23:00 (11 PM) | 20 Wed | Seattle       |
| 02:00         | 21 Thu | Boston        |
| 07:00         | 21 Thu | London        |
| 08:00         | 21 THu | Brussels      |

## Joining Information

[Zoom](https://mit.zoom.us/j/95356244879?pwd=NDBwZmxleTMwcHFpZG1MZW1tUXhVUT09)

## Agenda

### Day 1 Agenda

- <= 10m: Intro, Google Doc, Call for Scribes
- <= 10m: [TPAC Meeting](https://github.com/patcg/meetings/issues/53) led by [@aramzs](https://github.com/aramzs) & [@seanturner](https://github.com/seanturner)
- <= 5m: [Working Group Charter Ready for Submission](https://github.com/patcg/meetings/issues/52) led by [@aramzs](https://github.com/aramzs) & [@seanturner](https://github.com/seanturner)
- <= 10m: [CG Meeting Timing](https://github.com/patcg/meetings/issues/61) led by [@aramzs](https://github.com/aramzs) & [@seanturner](https://github.com/seanturner)
- == 5m: Break
- Remaining Time: [What is the right scope for functionality that should be supported in the first iteration of the joint measurement effort?](https://github.com/patcg/meetings/issues/56) led by [@marianapr](https://github.com/marianapr)

### Day 2 Agenda 

- == 10m: Intro, Recap Q&A, Call for Scribes
- Remaining Time: [Cross-Device Attribution](https://github.com/patcg/meetings/issues/58) led by [@martinthomson](https://github.com/martinthomson) ([Slides](./cross-device.pdf))
- == 10m: Closing and Next Meeting Planning

# Minutes

[Meeting Link](https://docs.google.com/document/d/1ijvnjqBvX5a_tGMHH6p9F31byBVwEvSFy0XlP6_za2k/edit?usp=sharing)

## Scribes

Willing day 1: Ben Savage, Charlie Harrison, Sean Bedford, and Mariana Raykova

Willing day 2: Nick Doty, Sean Bedford
## Logistics
### W3C Read All About It

[https://docs.google.com/presentation/d/1uahuT9ugb79YDEmpcYz3R4ymjCQg1G3S1JfhVpYVFrM/edit?usp=sharing](https://docs.google.com/presentation/d/1uahuT9ugb79YDEmpcYz3R4ymjCQg1G3S1JfhVpYVFrM/edit?usp=sharing) 

## Day 1

### Administrivia

Agenda Bash

### Intro, Google Doc, Call for Scribes

Read all about it links!

### [TPAC Meeting](https://github.com/patcg/meetings/issues/53) led by [@aramzs](https://github.com/aramzs) & [@seanturner](https://github.com/seanturner)

**Sean:** We talked and got about 30 responses. We got a room and though we expect about 30 people we may have a tight room because usually the event space expects 20. There will be a meeting for Tuesday of the TPAC week. 

**Wendy:** We are planning on hybrid participation for TPAC. 


### &lt;= 5m:[ Working Group Charter Ready for Submission](https://github.com/patcg/meetings/issues/52) led by[ @aramzs](https://github.com/aramzs) &[ @seanturner](https://github.com/seanturner)

**Aram:** We are close to completing the working group charter. We have merged a lot of things.

We have 2 small changes here. 



1. Wendy has added a link to the rendered draft.  [https://github.com/patcg/patwg-charter/pull/25](https://github.com/patcg/patwg-charter/pull/25)  Merged.
2. Sam was able to do a bunch of cleanup here. [https://github.com/patcg/patwg-charter/pull/24](https://github.com/patcg/patwg-charter/pull/24). Most of this is just basic stuff. Pretty unobjectionable and easy to read. Main differences are:	
    1. Cleanup over basic stuff, had intended to add but hadn’t added it.
    2. Plan to meet once every 1-3 months for a few hour blocks.

We can review this in more detail if ya’ll like, or just move forward. None of this seems to change the nature of the document. Any objections to merging these changes in? 

I’m going to merge it in. 

**2nd issue(s):** [https://github.com/patcg/patwg-charter/pull/18/files](https://github.com/patcg/patwg-charter/pull/18/files) 

**3rd PR:** [https://github.com/patcg/patwg-charter/pull/18](https://github.com/patcg/patwg-charter/pull/18) 

I see James is on the call. There has been substantial comments on this particular issue [https://github.com/patcg/patwg-charter/pull/18](https://github.com/patcg/patwg-charter/pull/18) and the discussion of the working group here. I saw, James, your comments earlier on this. I agree you’ve asked for input from a number of organizations. They have not stated that input or showed interest in providing this input. I don’t think it’s appropriate to continue to discuss this. 

There are some objections you’ve leveled with W3C process. I think the place to do that is with the W3C and not this specific document. It’ll be up to the W3C’s current process to handle those. I do want to come to the end of this conversation on the working group charter, so let’s keep it focused on the working group charter.

**James:**

I think we can draw parallels to this working group and the payments group from 2017. That group concluded they were able to deliver all the objectives of the group using general purpose APIs. That was well documented at the time. I’d like us to use the same approach. E.g. if someone wants to use the IPA standard that’s fine, they are not forced to do so because other options were removed from them. When we are talking about a working group charter that so clearly disintermediates… it’s very disappointing to me that the colleagues and participants on this call… legal review. It’s taking the W3C some time to provide horizontal review. I’ve made suggestions elsewhere of the sorts of general purpose APIs. The flawed notion of 1st and 3rd party. I’ve got more I could say on that, but you’ve asked me to keep it short. I’ll write something. One way to deal with that in this charter would be to take the approach taken on intellectual property. The data would be made available on “fair and reasonable terms”, simply expanding this to “data”. We can put things into charters, and this could lead the way on “access remedies” to avoid browser vendor control. It’s an innovative approach. So that’s my verbal input. I don’t think we’ve made much progress on resolving these issues. Another iteration to try to get this out. It’s well known that the W3C is going through a change to a different legal entity. May be worth going through another iteration, perhaps those members who were disenfranchised by the payments group and the decentralized identity group, another group which didn’t require any browser changes.

In Summary, I’d rather we spent time getting those things right here.

**Aram:** I see ekr is on the queue.

**EKR: One point:** the point about DIDs. These would require changes. They are not relevant to browsers right now.

**Clarifying question:** about “data” are you referring to the data that goes IN (e.g. Topics, the data which goes in).

**James:** I’m referring to the input data, so that anyone could implement Topics outside of the browser and have full access to the full data required to make that work.

**EKR:** Topics has an ML model. Are you saying the data to train that model? You mean the browser history data?

**James:** Yes. It would be available to those parties that want to implement the standard from the working group. Publishers / advertisers are free to decide if they want to implement this.

**EKR:** If the point is that parties who are not browsers have access to browser history, that does not preserve privacy.

**James:** I believe it is essential for competition for browsers to have access to this to allow competitive behaviors online.

**Aram:** To further clarify. When you say you want to see the browser history, you mean all the user’s browsing history across all the Chrome browsers? You’d like to see all that data they used to

 build topics available?

**James:** You’re focusing on Topics, and I’m not that familiar with it. Hard to answer definitively. If this group is to make a standard, and that requires data to train an ML, that’d be available to everyone, not just the browser. Anyone could implement their own version of that standard.

**Aram:** Let me use an example. 3rd party cookies are a standard by which any developer can theoretically collect data anywhere they have the ability to access that cookie. The data across all users across the entire internet is even now not available to every developer. You only see your own cookies. If we apply your proposed bar, you’re asking for even more than what is possible with 3rd party cookies? Are you asking for access to the entire data set, not just the 3rd party cookies where you have a script on the page, or every web visit everywhere on the internet.

**James:** If the group comes up with a technical standard which would use all cookies, and that’s the input which is required, then that would be available under fair, reasonable, non-discriminatory terms to any party that is prepared to sign up to that license. That license is likely to include obligations. 

I haven’t heard anyone propose a standard which would use all 3rd party cookies, but in principle yeah. 

**Aram:** I think I understand this point better now. You’ve used in your comments this term “general purpose APIs”, can you expand on that?

**James:** In payments we could have created a “general purpose APIs”. Problem was how to remove friction at checkout. We already have auto-complete, had we focused on a method of sharing data between multiple parties (merchants, handlers) we could have built a more robust set of APIs, credit card numbers predominantly. We wouldn’t have created a hook for browser vendors to interfere… this is the complaint, where they can interfere with which payment mechanism is top-of-list. This is well understood by the browser, proprietary decisions each browser makes. The fact it exists has enabled those business models to exist. What we need in a general purpose API… I’m not just talking in the abstract, I have a proposal, GDPR validated Sets. This would enable data sharing by parties who have signed up to a contract. It sits on top of the domain name model, enables data sharing under GDPR. The belief I share with google and the CMA is that if we align with GDPR we get a long ways in other jurisdictions. That’s a concrete example for how such a standard could work. That could take us a long way. 

**Aram:** I think that some of these issues are better addressed at the level of the specification itself. For “general purpose APIs” I think that’s a conversation better had on the specification. I’m not sure what you’re looking to do here. It sounds to me that on the one hand you’re saying that specifications for APIs can be used for more than one purpose. Your objection is that we are designing APIs specifically for advertising. GDPR validated sets seems to be a specific API for a specific purpose. I’m unclear how that’s “general purpose” but “Aggregated measurement” is different in that regard. 

**James:** Fundamentally, we’ve looked at the requirements for 1st party sets. That’s limited to the entity which owns all the domain names. GDPR creates a contract, people sign up to it. Standard contractual clauses. They get asked once for the contract. Anyone willing to honor the conditions of the contract does not need to ask again. Metaphor: “All text must be white on a black background”. Contract is intended to enable data to be transferred between different domains, it’s an artificial boundary, it upgrades that boundary to be aligned to GDPR and contracts. It’s about the what, not the who. 

**Aram:** Thanks for your answers. James, I see you have a question about DIDs.

**James:** I raised DIDs as an example to show how standards can be successful without needing any changes to the browser. 

**EKR:** I agree one can have a working group which is successful without changing the browser. I disagree this one can.

**Martin:** I want to clarify James’ point. In times past I dealt with header compression for HTTP. There was a data set involved in producing the compression dictionary. We ultimately decided we were comfortable that Chrome ran an experiment to produce frequency per character. We put that into the standard. We didn’t ask for the raw data. Each independently reached the conclusion that the standard was acceptable. If we build a system which is built on top of private inputs. We will have to make our own determinations based on the data we have - is the system acceptable to us. We cannot say: “Oh! We have to make the information public.” 

I would like to see objections of this sort broken down more. That point is relatively straightforward to dismiss. The point about “Generic APIs” is the same. If we set about to make a “Generic API”, we can have a discussion about whether those are appropriate. But, I don’t think trying to railroad things using the Charter is the right way. We have a simple charter, I’d like to keep it that way.

**Brain May:** Similar to Martin. Different phrasing. I think it would be appropriate for use to specify where datasets that are not widely available are used and consider the consequences of that.

**James:** In that situation Martin described around header compression the whole group was comfortable. If this charter will assume the same I am concerned. If we consider innovatio (the #1 driver of a trillion dollar ecosystem). Ability to apply different innovation. 

In relation to the data licensing, I’m not sure I get the point about breaking it down. I can do that. I’m concerned with words like “railroading” come in. I have specific concerns. Particularly concerned, smaller organizations cannot be in all the discussions. My company is 24 people. The charter is really important. If the charter is broad, those of us who are interested have to pay attention to a lot. If we are broadly happy with the charter we don’t. 

**Aram:** I think there are some interesting concepts in the PR you’ve put forward. Where it intersects with complaints with the wider W3C organization. We are subject to the rules of the wider group. That may wind up changing our charter and may not. I think some of the other stuff is better at the level of the spec. My inclination is to move forward with the submission of the working group charter, acknowledging that there will be some back and forth with the W3C. We may be asked to change it over time, but I do not see broad support for putting this broad restriction on what the group can and cannot discuss into the charter. The participants can find their way towards deciding what to do on specific proposals on the basis of those charters. I do not want to delay the working group charter going through this process. Unless there are some additional members of the group who support your objections, let’s move forward submitting the working group charter by Thursday, eastern time. 3 days to write proposed changes and get support. I understand you (James) would object to this. Does anybody else?

&lt;silence>

I want to give the group a chance to object…

&lt;silence>

**Brain May:** What are we objecting to?

**Aram:** Unless there are additional parties who support James’s objections, we submit the working group charter in 3 days. Let’s make it extremely clear. 72 hours from the end of this meeting.

James you can respond. Look forward to reading what you have to say. Doesn’t look like there are any other objections.

**James:** I have a busy schedule. I’ll do what I can within 72 hours, but that may not be possible. More importantly, is anonymity. I don’t make these points and arguments in isolation. Those other people affiliated with businesses that have restrictions. Other businesses don’t tend to come forward to the public domain. Would we be able to wave the question of anonymity so those who have objections can come to Sean and Aram. 

**Aram:** My feeling is we are a public group that works in public on this public document. It’s hard for the group to react to feedback brought in private. We are all subject to the same market pressures and concerns. I have a hard time seeing an allowance for anonymity. 

**Sean:** I have the exact same feelings. I’m not sure what it means to have private input in a public working group.

**EKR:** One use of anonymity is people can privately talk to the chair for advice about how to raise concerns and frame them. This is about consensus formation - and that is what we are doing right now -- and that can’t be anonymous.

**Aram:** That’s a good distinction. We are a public group run by consensus. We’ve set a deadline for moving forward with this (aside from James). I’ll note these charters are living documents which can be changed. With that, yes, James, I see the Charter cannot be changed without approval. Charters DO get changed over time. 


### &lt;= 10m:[ CG Meeting Timing](https://github.com/patcg/meetings/issues/61) led by[ @aramzs](https://github.com/aramzs) &[ @seanturner](https://github.com/seanturner)

Our charter stated we will meet 2x a month. That doesn’t reflect reality. Suggested change to charter: let’s talk about timing in general. Not the charter, the index page. I wanted to check in, especially as this is a later time, we did for people who had trouble with other times. Are people still comfortable with this pacing?

**Ben Savage:** I feel pretty good about the frequency of the meetings, but would like to raise the bar for the focus on the discussions. Looking back, a number of our sessions were unproductive. Would like a specific agenda / maybe slides to talk about, and maybe review those proposals for topics to make sure it’s a useful conversation.

**Martin:** +1 on what Ben said. This time agenda was fairly late. Having an agenda a week or two ahead of time, gives time for people to have the discussion on agenda and prepare. We could have a rough sketch of an agenda 2 weeks in advance and more fleshed out 1 week. Would be nice to have more time to put together material.

**Brian May:** If we have topics that people want to talk about, keep a running list of them and keep a prioritized list of them. Sense that we don’t have a whole lot of topics, but maybe wrong.

**Aram:** This week’s meeting has been fairly late, entirely my fault (Sean noted some of this was his fault as well). Was on vacation last week and didn’t have internet access when I anticipated to be putting time into this. Great vacation, but put trouble into planning. My apologies for this agenda being late. First time I’ve orchestrated an event on this time schedule. Appreciate other folks who have done this before. Hopefully this will happen earlier next time. I would like to drive the agenda setting more and earlier, but some of the difficulty here is that there is a lot of discussion going on, but not all is obvious in the repos. To Brian’s point, I would like a better sense of what people would like to focus on even further in advance. We can drive and facilitate things better. Would be great to think further out than a week, the thing we want to focus on the upcoming meeting. Things outside the context of the repos could be better brought to light. Worry here is that very often when we put issues out for specific things, the action tends to happen closer to the actual meeting time. I guess what I’m asking for is more help from the group for focus. We can focus on specific technical topics and documents people are generating, but to do so requires we plan further out. On me and Sean, and asking for groups support that these contributions are coming in regularly, so we can steer the discussions on what the group is focusing on outside of the meetings.

**Sean Turner:** From what I heard, 3 weeks we get agreement, then 2 weeks out we have slides.. (missed some of this). If we don’t have time, can always drop from the agenda. e.g. privacy principles and other we should have a standing item for those to put on the agenda.

**Martin:** Suggested 2 weeks not 3 but the principle is the same.

**Aram:** Makes sense, timing makes sense, we can endeavor to set these things further in advance. Generally we should not have a meeting within 12 hours of a holiday weekend in the future. Apologies. Juneteenth is an important holiday. Not intentional to undercut that, shouldn’t happen again.

**Sean:** TPAC is only going to be an hour. We are hoping to have a meeting in the first / second week of August. Difficult time but we are going to shoot for that.

**Brian May:** Timing + prep for meetings, that’s very useful for people not on this call. Can someone record this in an issue and make available to everyone else.

**Aram:** Going to merge the request here, I agree let’s make sure this is published on the site appropriately. We’ll make that happen. Anyone have anything else on this topic?


### == 5m: Break


### Remaining Time:[ What is the right scope for functionality that should be supported in the first iteration of the joint measurement effort?](https://github.com/patcg/meetings/issues/56) led by[ @marianapr](https://github.com/marianapr)

**Scribe:** Charlie Harrison

**Backup:** Sean Bedford

**Aram:** Acknowledging due to the short notice we will probably move the “meat” of this topic to the next session (day 2 of this sequence). I did think that there might be some useful grounds setting that we could do in terms of how we want to define scope and talk about what scope we want to set as the baseline, build on that, be better prepared for the discussion on day 2. Maybe this doesn’t make any sense, maybe we just want to hold to day 2, but seemed like people had come in to some extent with some ideas on what the baseline amount of MVP scope might be that we could build up in day 2. Issue 56.

Going to open up the queue to anyone that would like to start speaking.

**Mariana Raykova:** My goal with this issue is to converge on something very concrete in terms of the functionality of the measurement API that we can all agree with the present parties / browsers. Question on agreement on something cross operational, something of real value that everyone would be interested to have.

This would be value and of interest even if it doesn’t satisfy everything. People will be willing to give and take and restrict some of their requirements for MVP. For me, reaching agreement for this basic question, that might not address all uses, as long as it is useful for a subset is still a good reason to proceed with such a design that will be supported across browsers in a single API. Still needs to be value in this minimum functionality. What is our threshold for value?

In the past meetings we have heard a lot of different proposals with a range of functionality. From those discussions, there are two main questions:

1. Where to do attribution (on or off device)

2. Is a basic type of aggregation functionality a sufficient starting point or do we need more like machine learning.

I also want to put forward the question that, there will be systems issues in deploying an API. I think it’s worth starting with simplest functionality and iron out these other issues that won’t have anything to do with the functionality itself. Then incrementally build on top of this. Is this the way we want to go or do we want to start more complex.

Will prepare slides for next day. e.g. simple aggregation with fixed buckets that has already been implemented in some contexts. One question I want to pose: is this a good starting point? Should we take advantage of that fact that it is already built, or do we want something completely different.

**Ben Savage:** My thoughts on MVP. We’ve thought about this from the POV of ad sellers and buyers.

**Ben Savage:** From the buyer’s perspective, what is the purpose of why you need this? Buyers want to understand the effectiveness of the ads they are showing. They want to understand the return on investment on those ads, how to reallocate their investment to be more effective. We need to provide them with tools to answer these questions. What does that specifically mean? My opinion is that you need to support a type of measurement heuristic that is well-correlated with causality. We don’t want one heuristic that isn’t always well correlated with causality. Want to know how many conversions would have happened without the ad, this is the lift measurement use-case. Test and control users, one sees the ad the other doesn’t and you can compare.

Click-through measurement and view-through measurement. Ads e.g. on smart tv cannot get a click. I think these heuristics are important after lift measurement.

Cross device conversions. IF we don’t have this we will have an undercount. Important for some use-cases and not for others. e.g. smart tv ads critical, app install ad maybe less so.

Ad buyers want to understand relative efficacy. This means we need to support cross publisher measurement. Otherwise you will get double or triple counting of conversions and no apples to apples comparison. 

These are the baseline requirements

For the ad seller side, the baseline needs to support experimentation and calibration. Opposite side of the coin. Count how many conversions came from a cohort, split an audience into multiple cohorts and run experiments. Calibration. split audience into cohorts, and measure average conversion rate for cohorts to calibrate a system. That is important for the basic functionality.

I think machine learning is an important use-case, but want to tackle it next. Defer that conversation to the near future.

**Aram Zucker-Scharff:** I’m interested in defining the MVP first steps and minimum viable scope with these things because the meetings of this group are the grist of the ad-tech news industry mill. A lot of discussion happens around these meetings, can be difficult. Having clear goals / scope can help here. This is the ad-tech conference season. From what I have heard, a lot of people who are not technical but running businesses that would be affected by these proposals don’t think e.g. end of 3pc will come or think these proposals have a clear next step. I don’t agree with them but we can do a better job of being clear in messaging the wider community. Interested in whether we can define things in such a way that we can show a specific progression and outcome, hopefully lead them to … rather than building things that we are going to propose methodologies that will cause them to do extra work, at the same time we are doing extra work.

My hope is that by establishing MVP scope we can take these conversations and turn them into better understanding and a more active ability to bring input in from those stakeholders. Good to see businesses and ad-tech working on the same goals as us. This definition will be helpful for that.

**Martin Thomson:** Really pleased to see Mariana outline some of these things. Have been saying (and Ben has) similar things. Some sticking points we should discuss in the next session. Baseline of privacy. Different browsers have different policies (shipping cookies, providing these capabilities and maintaining privacy). Browsers have unfettered access to third party cookies, where privacy leaks are not regressions. Some negotiation to be had, but fairly positive we can agree on functionality outcomes, along the lines of what Ben outlined. Low functionality bar, but delivering something will allow us to iterate. Not delivering anything is a poor situation, and the ad-tech people will be correct, rather not have that outcome.

**Brian May:** My concern is similar to one you aired. I think we need to have a statement of the baseline use-cases and a roadmap of support. If we focus too much on proposals, broader industry will make assumptions that we don’t want them to have to respond to. If we have a roadmap, the people can use that to understand proposals in context of a larger plan. We need to work on this like a product group, not just an engineering group

**Luke Winstrom:** On the points that Ben made, pieces I am concerned about is the cross device piece and the privacy around that. Something on-device first before aggregating across devices will be easier for us to understand and explain from a mathematical privacy point of view. Also I think from the same lens, having a system that supports the rich attribution of credit to advertisements is doable from an on-device standpoint without having to do event-level aggregation. Event-level attribution on device and bulk aggregation is a much simpler story when talking about keeping user’s data private and delivering information to advertisers.

**Mariana Raykova:** Just wondering if we are hearing different browsers have different privacy thresholds hence those will imply different functionality. I am wondering if we can agree on basic functionality that meets every privacy threshold, and various browsers may extend in ways they see fit, would that be OK?  I would like to hear next meeting, high level statements that publishers and advertisers are used to, but I would also like to hear this translated to something very concrete e.g. fixed buckets, dynamic buckets, differential privacy budgets, are we trying to make it so that once ML comes in it’s out of the box and doesn’t require client changes. Probably requires a translation layer from use-cases to technical requirements. Will be valuable to have.

**Don Marti:** I think we’ve mentioned the interests of web publishers and advertisers, but at some point we need to take a step backward and consider the decision of the web user to decide to run this measurement system or not. The web user is the person who is being asked to contribute computing resources, take risks of any software quality problems that could result in the system not behaving as designed. As the user, where is the case to turn this thing on. At some point there is going to have to be a user-understandable explanation of that.

**James Aylett:** Couple of points. Ben discussing cross publisher measurement. I want to note that the issue in the current state is these walled gardens where its hard to get cross publisher. Additionally, offline conversions, etc means that we are only going to be able to assess a subset of activity. There are solutions to this and we are proposing a session (maybe in the next meeting) with some buy-side voices, but we could solve perfectly the understanding of what happens in a digital space and this doesn’t solve how this fits into advertising in general. We can compromise in some ways without losing the utility.

**Charlie Harrison:** Wanted to +1 the comments that have been made here. Should we try to figure out what a good deliverable would be out of the next meeting? Would it be useful to have for instance a stack rank of use cases where we draw a dotted line at some point where we have an MVP proposal and float that to the group with a longer-form discussion about it. Meeting tomorrow can’t produce a document that we can get consensus on but maybe we can come up with a strawman/format for figuring out how we make a decision and float that to the rest of the group. Feel that everyone is going to disagree on priority, but if we can agree on high level points, that is itself valuable. Things we disagree on, we should flag and try to resolve offline or in follow ups.

**Martin Thomson:** I like Charlie’s idea. I didn’t get in line to say that but it’s an important thing, we should identify what we all agree on. For me the number one is maintaining some level of privacy. A bunch of debates about what that means, important stuff to have a discussion about that. Worst case / at-scale debate should happen at the next meeting. To Mariana’s concern about different browsers having different thresholds, that’s non ideal. Would like this group to have a destination that we all share. So we can all share predictable behaviors in the one API we all develop here.

Event-level ARA  / PCM interop is a poor outcome for websites. Want to see something uniform come out of all this.

**Mariana:** This wasn’t what I meant. If we agree on something, then maybe individual browsers have extended functionality only on those browsers (not the common API). Not sure we will reach an agreement that we will _only_ implement those features.

**Martin:** Generally speaking we find what we agree on and ignore everything else. I would hope we didn’t end up with a bunch of per-browser specific extensions. Would rather see us get to the one API. Maybe in 2 years I’ll have a different answer.

**Ben Savage:** Trying to speak in the concrete. Concretely, I would like to propose a privacy bar we can agree. For all those use-cases listed, they are aggregate measurements. For those aggregate measurements to be considered private they should have 2 properties

1. Should not be able to be used to get definitive information about a particular person. PCM fails this, non-noised data. We need differential privacy / noise.

2. Propose that the semantics of the API should not point to specific individuals, but rather groups. Chrome event-level API fails this test as it gives information about a specific click.

**Aram:** Generally think the next steps as Charlie defined them is a useful path forward. In addition to identifying priorities we have to acknowledge, we will have priorities that are in opposition or very different. It will be good to acknowledge and identify them, knowing not everyone's priorities will be served by an MVP. As we think about ranking things, that might be useful to acknowledge.

**Charlie Harrison:** Perfect segue to two dimensions of MVP we need to discuss: one is functional requirements, the other is the privacy constraints. To the best of our ability, the way we can move forward with least argumentation and fighting is to separate these dimensions. It won’t be an effective use of time to rank privacy or DP constraints more important than cross device. It doesn’t make sense to do that. WOuld try to separate ranking and priorities for these two different dimensions. Let’s discuss agenda of next meeting (in 2 days time), but would be happy to punt some of the privacy conversations to a later meeting if we have enough time to discuss the functional use cases more fully. Want to avoid bunching these together, especially if it ends up with the fight about privacy vs utility.

**Brian May:** Tag along with Charlie. It makes most sense to define the utility, then how to make it privacy safe, otherwise we will get into endless swirling arguments about one privacy mechanism or another. We can all agree on the end product. In terms of browser consistency, we want to be aware of the side effects of an uneven offering. If one browser is offering less utility, publishers are going to start focusing on the other browsers.

For layout / fonts, you clearly want the site to look good, but if a browser doesn’t make a site money, it will not be used.

**Mariana:** I was wondering where we put the axis of complexity on this. Or also costs. We can very easily get into that situation. On the “semantics” point of Ben, there is a way of defining aggregation buckets on individual users. We can talk about “aggregation” but it can be fine-grained and you are only relying on the DP. We need to clarify what exactly this means in terms of the bar.

**Don Marti:** Also had a suggestion on Ben’s concrete use-cases. Definitive information about a particular person. “Definitive” is probably not a strong enough standard to apply, we need to think about the more adversarial use-cases of tracking. In the USA we have the whole supreme court thing, and Texas bounty hunters, and other geographies have low intensity conflict. Identifying whether a user is likely to be a member of the targeted group well enough to justify a particular kind of attack may be the better barrier. If you are an adversary with a limited budget to attack a certain number of members of the other group, then does this identify the person well enough to spend one of the attacks.

 \
**Ben:** Agree with what you’re saying. It’s necessary but not sufficient. APIs of the shape of PCM / SKAN, there is no DP noise. They should be off the table. If you add a microscopic DP noise, that isn’t real privacy either. It all eventually comes down to differential privacy. I agree, you can have an aggregation thing where the groups are size 1. you can have a group of 100 with 99 toddlers and you only know there is one actual buyer. Ultimately it comes down to differential privacy.

Simplicity, this is standards. This is the one time in my life I don’t want to move fast. Once we ship it we are never going back to change it. V1 will be stuck for a long time. This is the one time, it merits a more complex solution if it gives you a better privacy / utility trade-off. We are not realistically changing fast.

**Aram:** Idea of an MVP to do testing in a limited way is something that can be very useful. It is difficult especially for people not browser developers that they can’t do practical testing on. MVP concept can help serve. Lots of convos in the IRC about what needs to be prioritized in the definition (privacy / utility). I would like to discuss that prioritization more. We’ve looked at it as separate things. Separate privacy document and then in these proposals handle the utility aspects. not sure if that’s the right separation. Part of it is just, at some point there are use-cases that are existing that members want to preserve that will not continue to exist, of course they will prioritize the existing utility, that may be impossible to do. Is there another piece of this discussion, here is something that will definitely not be allowed.

**Martin:** Ben said something I objected to. Demonstrating we can work together to deliver something has significant value. Small extensions do happen over time. Counting 1 thing vs 2 or 3, could be something we can extend. Fundamental changes that require re architecting the system take longer time, restarting the process. If we don’t get the privacy right, that’s tough, but we can add utility over time. We can do something extra that doesn’t require fundamental changes. Some things worry me, e.g. not doing ML is potentially risky.

**Charlie:** Want to agree with what Martin and Ben said. I strongly believe that we should be extremely thoughtful with the overall architecture of the system so that we feel confident over time we can add functionality and use cases that may not exist in MVP and we don’t end up boxed in where it’s difficult to make changes or realistically, making changes becomes a huge burden for adoption. We need to use our brains and think really hard, to Mariana’s point I don’t think we’ll be able to come out of the next meeting with the exact specific functionality for the MVP because we need to be thoughtful and produce something maximally robust. I hope the use cases exercise will help us deliver this list and rank them in some ways eg red/yellow/green and structure proposals with that in mind about how compatible some of these use cases are with a future state. 

**Ben:** I like a lot of what Charlie said about assessing architectural compatibility with known extensions. Want to talk about sequencing. Martin mentioned adding utility can be pretty easy. A couple of things might make sense to move out of an MPV. We’ve been looking at internal data about how advertisers use our reporting products to understand priority, and a script to generate synthetic data to evaluate proposals.

What do people actually use? Vast majority of advertisers are not actually using the “purchase value” functionality. Most are just counting things. Can imagine a world where we just count things and then for the (less than 1% of businesses) we can maybe defer this. That’s something.

Breakdowns. Vast majority take the default view, just gives you campaign breakdown. That might be a reasonable place to start, adding additional breakdowns in a fast-follow that Martin claims is possible.

**Mariana:** Agree having DP is great. Better privacy story. I also know that looking at time passing, DP goes to infinity, need to be much more specific and concrete about how we think about DP. DP brings properties about worst-case adversaries. Do we think there is something intermediate, some other measures for privacy. Just saying we have DP, some epsilons equivalent to having no DP. I do think we have to think much harder about that when we’re trying to put something as a requirement in a baseline scenario.

Should spend some time to outline desired outcomes, what is viable to achieve. Should we be able to rule out some things? How should we narrow? Suggest people put comments on the github and list different concrete functionalities to answer or make a stab at paring down the options.

**Wendy:** worth being thoughtful for MVP related to expectation among users of the technology - hard to change direction after technology is established (stickiness of initial product).

**Aram ZS:** in his experience what people are saying they are doing and what they actually are doing with advertising technology is very different - things are much more blunt about how things are used.

**Braedon Vickers:** when prioritizing we should document how wide spread each use will have, e.g. uplift and cross-device attribution, what is the status of each of them in the current state.

**Ben S:** Agree with Braedon, other people should share data. Open discussion wrt DP -all useful systems have this characteristic. Privacy budgeting - how to bound all queries done in a certain amount of time. When talking about DP, if the system is interactive/adaptive it is much harder than defining queries upfront. Can we decide to live with queries defined in advance? - with a weekly reset so that you can make a new set of commitments. suggests that for MVP this will be OK, e.g. iterate on weekly basis 

**Talked to academics who asked:** Can we lean into transparency - publish all your queries, the semantics and predicates involved (not input data). This will allow external privacy researchers to have a look and understand what is going on. This will make things easier to analyze worst case adversaries.

**Charlie H:** THe proposal about transparency is interesting. Might be worth exploring later after I think about it. How might you implement this on top of IPA when queries are formed arbitrarily, etc.

Regarding adaptive queries - hitting this question with the attribution reporting system , not having adaptive queries has been a bit of a road block. Queries end up being too noisy - a fix can be to be able to query at campaign level and then decide whether you want to dig deeper - a week might be too long of a period to decide a next query. Adaptivity will be something important for MVP. You can pay for it with a privacy budget, it is still a useful choice to offer.

**Meta question:** chatter about reordering discussion about privacy and utility use cases, should we spend a next session to discuss this - should we first discuss privacy or functionality?

Aram. Supports the suggested discussion above. The transparency idea seems interesting and it could be helpful - fear comes from uncertainty how data is used, make sure it is honest transparency

**Luke:** on the transparency - benefit if explainability, easy to articulate things that are happening in the system.

**Aram:** how should we order the discussion for the upcoming session.

**Martin:** rather to deliver on things we promised to deliver, i.e. functionality and then discuss privacy and come up with a privacy baseline in six weeks time. We should aim to agree on privacy principles out of that meeting.

**Brian:** first define utility for advertising use cases before talking about privacy (maybe some very basic privacy principles to frame the discussion). If we cannot start with what we want to do and then decide what are the privacy issues, then it seems hard to proceed.

**Aram:** privacy principles will arise from the discussion of utility - maybe makes sense to focus on utility in two days and then going for privacy

**Brian:** somebody who is advocating for privacy first to explain

**James:** we will go in circles if we go with one of them first. Start with a strawman for privacy, define utility then, and then go back and refine privacy. We should decide architectures from starting requirements on privacy. For each use case, decide whether it can be done with respect to the privacy bar - too vague to understand which use cases might not be possible, use cases themselves have variability

**Ben:** agrees with James. The realistic privacy bar is tough and significantly curtails the set of feasible things, this will help moving faster, e.g. if we agree on noisy aggregates, then rule out PCM and Chrome event level API. This will help quickly converge on an answer.

**Aram:** privacy sandwich - privacy, utility, privacy. What are we doing in the next half - go with the sandwich sequence, is there any objection?

Martin - continue with the agenda as proposed, give us a better idea for utility. Then in the next meeting, that’s 6 weeks away, discuss privacy. 

**Mariana:** Agreeing on aggregates sounds more like functionality than like privacy.  Ben described "noisy aggregates" as a privacy feature, seems different to me.  Agree with Martin: proceed next time with what we already had planned.  Go for defining the functionality we want to achieve — we can discuss whether the output is private, this can be part of the discussion of functionality, but once we agree on what we want to achieve then we can turn to techniques.  Discussion of functionality will let us ask whether there are trade-offs in design decisions to achieve it.

**Aram:** standing proposal continue with what was proposed 

**Charlie:** clarify what we are going to talk in two days, e.g. the question of ranked list of use cases, wants real clear understanding for a deliverable, maybe initial probe

**Mariana:** Suggestion - to go through possible use case scenarios and do the ranking that you are suggesting and see what is there in people’s minds and the question will come up - for each functionality we are defining is this a privacy concern? For most we can say we can make this happen with differential privacy but we can discuss concrete scenarios and say this thing has privacy concerns and discuss the output. 

**Martin:** Just saying we move forward with the Agenda as set.

**Mariana:** I think there’s this question of the next meeting and our output 

**Aram:** maybe something about the axis for ranking, extension for what we used this meeting for. Prioritization - what is the shape for the outcome for next meeting, what methodology we should use to create the ranking.

**Charlie:** have meta discussion

**Aram:** It sounds like concrete strawmen for us to discuss should be a big part of day 2, along with an opening meta discussion. 

**Brian:** Ben has a good list of things, maybe can reproduce that in an issue. We should start with utility before privacy because there are many more dimension to privacy, i.e. costs and trusted parties etc.


## Day 2


### == 10m: Intro, Recap Q&A, Call for Scribes

**Spt:** overview of links, including code of conduct, cla, patent policy, antitrust and competitive guidance. If you have questions, ask the chairs!

**Aram: reviewing yesterday:** WG charter, need any issues by tomorrow, submitting WG charter then.

TPAC session is scheduled for Tuesday; in person and remote participation. Maintaining this meeting pace.

Rest of conversation was on scoping / issue 56. Conclusion: we want to engage strawmen on utility and cross-device attribution. Next step is to review strawmen, including from Ben. Structure our conversation for today to start with.


### Remaining Time: [What is the right scope for functionality that should be supported in the first iteration of the joint measurement effort?](https://github.com/patcg/meetings/issues/56) led by[ @marianapr](https://github.com/marianapr)  /  Remaining 


### Time: [Cross-Device Attribution](https://github.com/patcg/meetings/issues/58) led by[@martinthomson](https://github.com/martinthomson) 

**Mariana:** I have a simpler proposal for us to start with.

**Slides:** [https://github.com/patcg/meetings/blob/main/2022/06/21-telecon/PATCG-June2022.pdf](https://github.com/patcg/meetings/blob/main/2022/06/21-telecon/PATCG-June2022.pdf) 

[slides] [Zoom muting issues]

**Mariana:** agreement about common API across browsers. API may not meet everyone’s complete set of requirements. And different browsers might have different extensions to a common API. Should we have simple but valuable before going to full complexity? Would need a way to extend the initial functionality, because it could be difficult to migrate from v1 to v2.

**Mariana:** main question is whether we focus on aggregation, or also include machine learning functionality necessary for more use cases? And attribution on device or off device, which will have security implications for the system. Fewer things we send off device is probably better for the system.

**Mariana: strawman proposal:** aggregation only, no ML. What happens on device – registration of events (clicks, views, or other events?), what metadata is attached (timestamps, geolocation, other?). Attribution could be done on user device or in aggregation service. Enforcing sensitivity limitations, how much a single event contributes to a particular calculation – could also be done on user device or in aggregation service. Aggregation service (off device) has to do the aggregation, and budgeting of adding differential privacy noise.

**Mariana:** starting as simple as possible, only aggregation with differential privacy, with a fixed number of buckets on the order of 2^20-32 (a “relatively small number of buckets”). Sensitivity bound is fixed and applied on the device. Aggregation service could be queried with adaptive queries across fixed buckets, and different epsilon for different queries. 

**Mariana:** Chrome Attribution API proposal would have 2^128 buckets. Apple PCM would have only 8 buckets but no differential privacy. Mozilla-Meta IPA proposal would have attribution on aggregation service. Microsoft measurement proposal would have much more flexible aggregation buckets. 

**Mariana: missing functionality from first strawman:** This proposal would have fixed aggregation bucket, and so wouldn’t have aggregation granularity informed by different queries, aggregations on subsets of attributes for a particular campaign. This wouldn’t have different sensitivity bounds per query, where some experience has shown that L2 bounds are sometimes better, or L1 bounds are sometimes better. Ideally each query could specify a different sensitivity bound.

**Mariana: strawman functionality:** adaptive query and differential privacy. A query is defined by a set of bucketing functions. @@ data that is known to one party about impression views ??. In most applications, likely want to do bucketing only on impression data. And the query specifies a type of sensitivity bound. And the query specifies the epsilon value for DP enforcement. Sensitivity bound enforced by the aggregation service, rather than on device.

**Mariana:** optionality for extensions and API flexibility for future use cases. For an architecture where we send secret data into an aggregation service, extensions of functionality would require a change to the aggregation service. We should change the data sent off device only when strictly needed, shouldn’t be hard to change.

**Mariana:** threat model – start with two parties in order to minimize the trust assumptions, rather than involving many parties where many-more-than-2 are non-colluding. Consider malicious for privacy, but semi-honest for correctness. Strictly we would expect that the servers not learn anything. Instead relax that the parties might learn some leakage, but allow that leakage with some differentially private guarantee. The servers can learn counts, but not linkable to particular impression or conversion data. Propose client input authentication is optional. Could use trust tokens as an approximation of trust in the client. Related to questions of fraud for the MVP. Come up with an acceptable cost.

**Ben: split into:** functionality, privacy, security. [Target privacy constraints](https://github.com/patcg/private-measurement/issues/17): API should only return aggregated, anonymous information. Should not be able to link counts to a particular individual through any mechanism. Differential privacy is necessary. And aggregation over some set of source events, should we require a minimum number of events that went into the aggregation. E.g. “there were around 3ish conversions from some of these 100 people” makes it easier to explain to people how this is private, because people are familiar with statistics about you as part of a neighborhood or company or group. If there were breakdowns down to a single person, we could still add differentially private noise, but will be hard to explain to people why that is still private, even if the group is only 1. In the worst case scenario, there’s no difference, because you could have 99 sockpuppets. Or it could be 100 real people, but you already knew that the others didn’t convert. Do we want to have a minimum number of entries in a bucket?

**Ben:** information leakage over time – how much information leaks each week? What is the total amount of information is leaked to the source site? Depends on average targets. But the distribution is quite a wide range. For people who visit lots of sites might reveal more information about them. IPA proposal varies from Google proposal in being global rather than pairwise by sites. How do we want to add up the information leakage?

**Ben:** [target ads measurement use cases](https://github.com/patcg/private-measurement/issues/16) for MVP. For a given query, the output is a histogram, with a number of buckets and the total for each bucket. Unclear why 2^20 buckets (or many more) are needed. Breakdown keys might be 10, 20, 100, but you might want to do separate breakdowns.

**Mariana:** if buckets are fixed up front, query can’t define the granularity. So the bucket pre-definition has to predict every potential granularity of buckets up front, which is represented in the large number of fixed buckets.

**Martin:** number of buckets will depend on an architecture, which will lead to different conclusions. I don’t have strong opinions, but would like to talk about the function in the abstract, and then more sensible comparison of differences between the options (what happens on device vs in aggregation service).

**Charlie: number of buckets question:** more obvious an issue with fixed keys/buckets where buckets are set on the client, but a fundamental privacy property because the mechanism to reduce the number of aggregation keys sets a hard limit on the number of buckets in the histogram. For example, PCM proposal is pretty good because it has such a strict limit of the histogram buckets, which makes it very hard to do pervasive tracking. It’s not the only privacy lever, but is an important one to prevent fine-grained histograms which might make it possible to assign a user to a histogram bucket.

**Ben:** -1 on PCM providing good privacy protections. Per Martin's paper  [[https://mozilla.github.io/ppa-docs/pcm.pdf](https://mozilla.github.io/ppa-docs/pcm.pdf)], I think there are substantial tracking risks described in this analysis from the PCM. But a large number of buckets doesn’t seem like much of a restriction. Maybe instead a minimum number of people in a bucket, with a finite number of buckets. I don’t understand how it helps to fix the buckets on the device.

**Charlie:** one class of proposal could fix the number of buckets, like PCM does. But restricting the size of the histogram is the general principle: e.g. each query only gets answers with a certain number of buckets. Privacy amplification kicks in when the number of buckets is smaller than the number of users, especially when the number of buckets are much much smaller than the number of users. Still a nice property that you can’t learn lots of things about lots of people at once.

**Ben:** pigeonhole idea that if you have many more people than buckets, at least some buckets will have lots of people. Or should we have a minimum number of people in a bucket?

**Nick:** Could you put more detail into the privacy protections stemming from bucket count? Does that help to explain to users if actually we don’t have protection that it’s real users?

**Ben:** It guarantees a minimum size for the query for the honest application, where you don’t have sockpuppets.

**Charlie:** separate whether it’s a minimum number of source events, vs a minimum number of conversions. Those two would have very different utility implications. That might be something we could get lots of data on, because ad tech could check their existing data. Should check real data that it doesn’t tank utility, especially because it’s not the key privacy protection / potentially weaker privacy threat model.

**Mariana:** abstract functionality vs protocol side. Since (if) we’ve ruled out ML for complexity, we should be aware of how complex it would be to do the other computations we’re considering. We should look at use cases/functionality, but we should stay cognizant of how to concretely implement that.

**Luke:** computation you want to do vs. can do once the data has left the user’s device. When you do the attribution on the device, you can guarantee to the user that the computation had to happen on the device. Whereas if a join key is sent off device, the user can’t have as high a confidence level of what happens with the join elsewhere.

**Martin:** in some systems, data that leaves your device leads to unknown computation, but if there is aggregation, there will definitely be some calculation happening off the device. Suggest we decide what the aggregation calculation is. For a MPC, given constraints about mass defection, we can give strong assurances about how the data is aggregated.

**Luke:** it sounds to the user like I know what my line item is that’s being added up on the service.

**Martin:** but if you release the single item, you’re still trusting that the system is adding up/aggregating only in the expected way.

**Luke:** yes, you’re still trusting the aggregation system to aggregate. But you’re making different assumptions of trust, or different potential things that are learned if/when trust is broken. In the case where everything breaks down, does the user leak a timestamp leak of their browsing history, or just an attribution report? Should have a worst case scenario of what happens if the entire package of data about you is learned.

**Charlie:** +1 to this framing. MPC shouldn’t be considered a panacea. But also trusting the MPC less and less will make options less and less useful, like adding noise on device, which often fails the utility goals we might have for the system. I see a lot of value in simplifying the server-side component, but you might lose some of the power of getting better utility for the same privacy cost.

**Aram:** I think that having off device systems does not mean we cannot provide **any** privacy guarantees. We can build out systems that can provide privacy off-device.

**Ben: on device vs on server:** other downsides of on device attribution include having to add time delays (otherwise timing attacks are very easy for re-identification); random time delays is the best you can do, but only works with lots of traffic. Adding long delays has a utility cost that we’ve seen in practice from PCM/SKAdNetwork. And cross-device is very important for utility, as so many people buy things on a different device than they saw an ad. Re Luke, I don’t think the worst case breakdown that Luke referred to actually is different. In those lots-of-buckets case, you’ll still have something uniquely identifying.

**Aram:** in the same way that some challenge moving calculations to their browser because they might not have trust in browser, there might also be lack of trust about anything that’s limited to on device. I don’t think that on-device or off-device are either going to be a solution that guarantees user trust. Users are having issues trusting their browser, their devices, and off-device systems, no approach is going to guarantee positive news headlines

**Charlie:** I don’t think on-device attribution means that we can’t send immediate reports. You can send a report right away if some of the time you are sending null reports. [?] On-device vs off-device attribution is a key fundamental design decision we need to make as a group. We should try to make that decision by looking at the most data and use cases and tradeoffs; needs a holistic decision. Could take a long time listing pro’s and con’s. Maybe we should have a separate topic on this and prepare adequately. Fundamental architectural decision we need to make before we can work in earnest on a detailed technical proposal.

**Brian May:** hard to follow all the implications of bucket sizes, differential privacy and noise. Is there a simpler explanation of the issues, that could be conveyed to people who are not immersed in the topic?

**Aram:** might be useful to have simple, Wikipedia-like versions of these concepts.

**Ben:** via John Wilander, looked at different levels of threat: curious, compromised or compelled. [Added a new issue](https://github.com/patcg/private-measurement/issues/18). If any single entity is curious/compromised/compelled, security guarantees should continue. On the server side, if any one service is compromised or compelled, we wouldn’t want user privacy to be leaked. +1 to Mariana on the malicious security model for maintaining privacy. Per Luke, should we also consider what happens if all the parties, or some of the parties are compromised and what is revealed? I’m okay with not expecting multiple parties to be compromised.

**Ben:** risk of compelling Google or some browser vendor to ship a special backdoored updated version of the software. I currently have no means of validating that my Chrome or Firefox installation matches the source code.

**Sean Turner:** Plan - get to the queue and keep going on use cases. Try to save an hour at the end for cross device topic. Maybe some time for use cases then X-device.

**Brian May:** Just wanted to comment on Ben’s notion that we only need to be concerned about a single compromise. Need to take into account that a government would compel all participants to provide data and that if that happens it should not represent a significant threat to any one person


### Use Cases - CSHarrison

**Charlie:** Tried to compile a probably [incomplete set of use cases](https://github.com/patcg/meetings/issues/56#issuecomment-1163859341). Maybe have talked about in forums here and there. Happy to add if we have something feasible. The end goal is to have a unified set of a small number of features that “people can paint different colours” of how happy/sad we’d be if we would be able to support. Following from that can write strawman proposals and map between the two.

Will quickly go over the features I’ve added here for consideration:



* Use cases: [https://github.com/patcg/meetings/issues/56#issuecomment-1163859341](https://github.com/patcg/meetings/issues/56#issuecomment-1163859341)
* Basic functionality - aggregation counts, VT conversions, 
* More sophisticated - aggregation sums, averages, bucketing, multiple breakdowns per event. Comment in Ben’s issue to have constraints on the system at query level to get more from it. Adaptive queries - multiple queries based on results from previous queries
* Attribution scope: App&lt;>web use cases, cross device, cross pub/channel, online&lt;>offline
* Attribution functions: last touch, multitouch (various complexities)
* Third party reporting
* ML training/optimisation - simple optimisations, SGD for small/large networks, decision trees
* Near real time reporting

Need to make sure some of these are satisfied because it’s how the ecosystem currently works. Don’t want to create a situation where this is 1 party only doing the work and we put all of the efforts on those companies.

Can open to questions or dive into more detailed ones.

**Braedon:** Just a note that it seems like a lot of the use cases are more like functionality to implement the use cases, particularly in more complex queries and ML. Would be good to better understand what these things are used for by some of these queries.

**Charlie:** Use case vs features - maybe this is a useful breakdown. Some are supported by multiple breakdowns. Some are so low level they apply to a wide range of things, so in some cases it’s hard to say exactly. 

**Sean:** app-web, cross-device, cross-publisher – these are just features of the measurement use case. What is the use case that we are trying to solve – measurement, attribution, targeting, optimization?

**Ben Savage:** How sad would we be about certain things not working? When it comes to attribution - I propose extending it to simple multitouch. I think we can do this efficiently in a arithmetic circuit. Was assuming more complex off the table because it’s harder to do, maybe Shapley values are impossible. Simple MT should be tractable though. For 3P reporting, what are you referring to?

**Charlie:** Common for an advertiser to work with multiple different measurement providers who aren’t the same as their DSP - they do this for a variety of reasons, eg provider A will check provider B’s work to confirm they aren’t lying. There are other sub-use-cases too. It is about supporting that ecosystem and ensuring how we can offer multiple measurement service support to not cause utility hit for advertisers. This is probably underspecified right now. Might be good to have adtech players in the room if there’s appetite for deep dives.

**Nick:** How should we evaluate use cases and what sort of metrics should we get? Many people have many use cases, lots of data could be used for something. What is our sense of how we’ll decide on the tricky question of complexity vs utility?

**Charlie:** Important question, not quite there yet in terms of having an answer. Need to see where we have consensus as a group and take if from there. I expect a lot of us see these things and think it isn’t feasible to support. Can agree for some of those. One of the goals should be to produce a small set of things that we need to argue about for longer to make decisions. 

**Brian May:** 3P use cases - in my experience there’s very little trust between people and everyone wants at least a second source for pretty much anything. Ideally as many sources they can triangulate over as possible. We’ve been focussed on small things that people want to measure and ignored fraud, billing, and many other things that are part of the ecosystem

**Charlie:** +1 Brian. A few of us got together after the last meeting to hash out some of the security threat model that Erik had a topic on last time. This is deeply ingrained in the threat model work. We want 3P reporting because we don’t trust and also want a system set up so the parties can’t influence the results of others. In attribution reporting API, support for 3P was added in some sense for X-Pub, X-channel, securely, so that you didn’t need to trust all of the parties involved to get the “right” answer. Would love for you to contribute if you consider yourself an expert here to move on from our simplified model. Erik was trying to map out involved parties and what their goals and motivations are. May want to bring to broader group

**Brian:** I wouldn’t say I’m an expert but would love to consider corner cases to try to pick apart.

**Alex:** Clarifying - is the reason 3P listed because the idea is that the baseline would be that reports just directly go to advertiser or publisher? 

**Charlie:** Not necessarily this is the baseline, I listed it because I think it’s very easy for us to accidentally design something that messes up this existing system. If we do do that, we should do it consciously and not accidentally. E.g. with IPA they have designed something that has per-advertiser privacy budgets. Details not all fleshed out, but there’s some way of being able to delegate stuff to third parties. Those two together potentially introduce a security issue though, e.g. if one party consumes all budget before the second, then you have a DOS attack. 

**Alex:** To ensure I understand, it is to make sure that what we design can be shared (budget in your example) in a way that makes sense for how some of the ecosystem works today.

**Charlie:** Want to design in a way that maintains the status quo of supporting 3P measurement as much as possible. To go one step deeper, for longer term designs, might be good to look at underlying use cases of why advertiser is using these different parties and identify root cause. Would be good to reduce complexity, but this is a massive rearchitecture. 

**Alex:** Not only that, but it would take much much longer to get to a standard. I doubt we have the right crew of people here to do that though

**Charlie:** I share your concerns, I put this bullet so we can have these kinds of debates.

**Don:** Looking at this as a unified set of a small number of features, it looks like a bottleneck is what happens when it’s time for the end user to consent to it? Looks like it would be difficult to explain to an end user and especially difficult to understand the difference between the current user data ecosystem and the mathematical properties of this system. Two approaches - more math and CS education for end users, but may be interesting to do more early on user research on what people would actually consent to and filtering functionality to something that can be explained well enough. Would be a shame to build a perfect “deluxe” system that meets a variety of needs but then when the user looks at the dialog, they say “that looks like something I don’t understand so will leave it turned off”

**Charlie:** I’m sure others have opinions, my feeling is that target privacy in MVP is that we can describe this in ways users can understand. Explain aggregates, reidentification, etc. I think this has been shown to be understandable to people. How this relates to consent, I’m less sure, but if the option is to add more features which would make it harder to explain, that may be a tradeoff that we’d be willing to make

**Martin:** I agree with you Charlie, it’s possible, but not perfect, to get to a plausible story about how this works that roughly corresponds to reality. There is some hope, with some caveats. 

**Don:** Need to keep in mind that a lot of existing 3P cookie systems already use language around security and pseudonymity guarantees, and that it would take user knowledge of system implementation to differentiate a 3P cookie system that makes claims of this from a system that mathematically guarantees privacy behaviours.

**Martin:** Our discussion on threat model highlighted the importance of dealing with this from a threat model perspective. Longer term we may need fundamental shifts. The potential to have multiple people taking information from what is known to be a limited source is going to lead to suboptimal outcomes if they have to share. Those are the sorts of things we’ll need to work through. I do think we need at minimum to be able to delegate, may be 100%. Question on redundancy is more about how disruptive we want to be to the existing ecosystem. It’s predicated on infinite supply of information and we’re talking about taking that away. I suspect it may be quite a lot of damage, but we may need to support a transition period from current state to maybe eventual “1” 3P end state

**Ben:** On the concept of 3P reporting, I linked to a [FB newsroom post](https://www.facebook.com/business/help/313903878988514) where we talk about verification of partners supported on FB. This is for ad viewability metrics - “was my ad actually viewable”. Maybe you don’t trust FB metrics and want an external party to confirm. My assertion is that this isn’t affected by removal of 3P cookies. None of those partners would be affected if you removed X-site tracking. The only allocation we’d need to make for third parties in a private measurement API would be if you don’t trust conversion counting. E.g. FB generates 16 conversions, and you want someone else to check their homework. It’s possible you completely solve that problem with the existence of a private measurement API, for example FB may not be doing the counting any more. There’s an MPC consortium with independent parties who do this instead. Maybe we’ve solved that use case entirely. Sure, someone could still lie by generating fake reports like click stuffing, and you could employ a measurement partner with local information to validate those clicks. We should contemplate the case that we don’t need this backup/double checking


### [Cross-Device Attribution](https://github.com/patcg/meetings/issues/58) led by [@martinthomson](https://github.com/martinthomson)

**Martin:** Conversation about what it means to have this in scope or not. Trying to avoid putting thumb on scale - call me out if I have done this. Some trade offs will be aspects of design and I don’t want to get into that right now.

Walking through slides

**Slides:** [https://github.com/patcg/meetings/blob/main/2022/06/21-telecon/cross-device.pdf](https://github.com/patcg/meetings/blob/main/2022/06/21-telecon/cross-device.pdf)

Utility:


* Both FB data and Google data shows that there’s some utility here (slide 6)
* Search is a key component of the transition between devices.
* Study that took features from desktop and mobile and saw reasonable gains in ML models for predictability (slide 7). I believe these to be lower bounds on the amount of tracking involved at 20% of cross device tracking.
* All of the discussion on utility shows that having cross device is “better” for some definition of that, with few real drawbacks for utility.

Privacy>



* More utility = worse privacy is the assumption (slide 9)
* Consider who can link devices - browsers and platforms, possible for same vendor, maybe possible across different vendors
* Cross-device login maybe allows for this, so does heuristic tracking (IP address etc)
    * Probably don’t want to consider these, due to dire consequences

Walk through of more privacy/more utility (slides 11-12)

Abuse vectors - misuse of measurement for tracking purposes and not for measurement. If a site can link devices then it amplifies information by number of devices, and the measurement system doesn’t know.

Defending for abuse - differential privacy, need more noise with more devices. If we link devices, need tighter bounds.

Competition effects - which actors benefit?

Baseline - lots of actors already in a position to link activity across devices. Coverage is likely not uniform across measurement providers. 

Leaking reach of devices - information provided by someone could leak out. This could be in the shape of revealing # of people with same device to a large audience outside of platform operator. E.g. Chrome/Android, others may be able to gain insight on numbers of devices in jurisdictions at the level that Google themselves may have

Change - when we change something, the competitive landscape is necessarily going to change too. We can define what we can measure, but that also defines the outcomes, unavoidably.

**Alex:** Good news is that the status quo is shit. We can perhaps build something that doesn’t have to compete with status quo. Anything here will be “quite good” by comparison. Nobody believes that X-device works very well. Nobody is extreme maybe - most don’t believe it works well.

**Charlie:** 2 quick comments - when we start off with utility and came to the conclusion that there’s only upside, then we discuss how we can enforce stricter privacy constraints. Need to be aware that could cause utility issues depending on how we design the system. We should be aware of this when doing privacy scopes for users across devices. The other thing I wanted to talk about is a core design decision for X-device which is who defines the device graph and who can access it. You can do a grid of solutions around that - is it maintained by e.g. the browser vendor, or ecosystem, and which parties can access. The IPA proposal is one cell in that design space of “ecosystem and anyone”. You mentioned a concern around this of exposing device graph reach or similar. E.g. if FB exposes their graph and I use it, I can determine an estimate of how many logged in FB users there are. There’s another aspect of this that is problematic, many businesses have a policy for sharing user data, and this system despite how fancy it is, I fear that making company device graphs available will be very difficult due to company policy around data sharing. Otherwise, agree with most of what you said

**Martin:** On utility/privacy - I glossed over that if you’re able to get privacy gains by recognising multiple devices pertain to same person and budget accordingly, you might still miss the fact that this is the same person, and a tracking adversary knows. You need to account for that in any design, so there may not be any strict privacy gain. I agree on device graph - number of ways we could split this and there are e.g. different competition aspects. I tend to like the IPA approach in that if we do something, the companies that have legal, policy, moral challenges will find it challenging to use. For instance if Google finds it too difficult they could use FB’s device graph to drive attribution, it may be weird but is understandable. Providing own device graph leads to a poor set of outcomes due to gaming of the system.

**Ben:** Want to respond to Charlie - on worse utility because of capping - that’s based on a different baseline - in the issue I filed about privacy constraints, tried to frame it as an upper cap on the amount of information system reveals. If you pick that as your constant baseline, if you do this without X-device, you’ll need to do some analysis on average number of devices and add more noise based on that understanding. There will be actors (like FB) that know all six devices belong to you, so you’ll just need to bake in the noise. It’s only a “loss” of utility if you designed system A and B with the same epsilon. On second point on company policy that I don’t totally agree with - it’s interesting, FB certainly doesn’t want to give out user information, we’ve made lots of commitments to that effect, but if it is in aggregate it is quite different. All of this is about aggregate user information, if you go to e.g. GA that is some form of user information already. There’s a big difference between learning something in aggregate vs telling people what a specific individual does. We don’t want to reveal individual device graphs.

**Charlie:** I think it’s more complicated than that, we can make guarantees on the output to some extent for a threat model, but that model won’t be the same for some company policies, who may choose to never give out their graph. There are more sophisticated models that involve the aggregators colluding. We have to be thoughtful about budget scope too, because user data potentially sent to many different parties and advertisers. Privacy unit is per-site potentially so because of a lot of different sites, that aggregate claim for a particular user is not as strong. There’s a lot of nuance, maybe if we can design something “super super airtight”, but I feel like a fundamental thing is that this is different from other privacy/threat models due to pervasive sharing that is new.

**Nick:** Agree that there’s not a direct privacy/utility tradeoff. We should consider more impacts on privacy beyond just affects on DP of the system. We should compare to harm reduction for status quo and other incentivised X-device tracking. People may have concerns about sharing this graph, even if we could design a system that doesn’t reveal this data to queries, if we combine data, add more match keys, etc, even with minimal privacy risk, maybe one day e.g. the NSA would be able to use it due to proliferation of match keys. We should think about the potential risks of how it could be used. These are privacy risks, not directly around utility.

**Kleber:** Concern shared with Charlie about X-device linkage to the API introduces something new and different to other privacy threats we are talking about. The new ads specific APIs we’re building have one really fascinating advantage over general purpose APIs that advertising has relied on - they have purpose limitation built into them. By introducing these APIs the browser has understanding/control over what the data is possible to be used for. If we can add in this limitation - great. Introducing X-device graph has changed purpose limitation API. The purpose limitation has now gone - even if exactly as Ben said, we do aggregation, the entire system allows the party to measure attributions, conversions, the device graph is now available to others and can be used for other purposes.

**Ben:** I don’t understand what you mean about how it isn’t purpose limited - if we design an aggregate measurement with DP where it joins source and trigger to make contributions, whether those events come from same or multiple devices, I don’t understand what you mean that limitation is gone.

**Kleber:** The threats that came up in the discussion of sharing device graph - learning about that graph is a way that this API can be used by another company to do something which is not “measure conversion rate”. 

**Ben:**Maybe there’s an edge case attack, which is a side effect, but it definitely isn’t a “purpose”.

**Kleber:** Agreed it’s a side effect, but what you said is if you’re e.g. Google and plan to use information for attributing conversions, then no matter what else happens you’re fine and haven’t violated promises about data use. But suddenly, the data can be used in new and different ways if someone who is not Google can leverage the graph to learn something new. In this case, Google has no control and the purpose limitation is no longer the guarantee it was before.


### Closing

**Sean T:** Thanks all for showing up. Secondly, looking at meeting in 1st-2nd week of August. Doodle poll coming soon. Trying to move WG charter forward. Want to confirm if objection or clarification on charter

**Martin:** Objecting to substance of James Rosewells objections. I don’t think there’s anything more for us to do. I think they have no bearing on what we should take to W3C

**Nick:** No worries or preference about timing, but no specific objections to the charter text, just questions/concerns I had about the PR. 

**Sean T:** Ok, seems like we have rough consensus on path forward. Process is set up for more discussion later and that is ok. Will loop with Aram and figure out what we will do.


#### == 10m: Closing and Next Meeting Planning

_From James Rosewell who was not able to attend the meeting in person. The[ GitHub discussion](https://github.com/patcg/meetings/issues/52) in relation to the working group charter has evolved in the past 10 hours with x4 topics that other people who agree with aspects of my objection are wishing to see addressed prior to submission for the W3C charter group. Many further questions have been asked and are yet to be answered. Some of the most recent posts contain a great deal of content that will take time to assess and respond to either offline or online. It is in everyone’s interests for these matters, some of which relate to the W3C Antitrust Guidelines, being addressed prior to submitting the charter to a wider audience. I request time at the next meeting to answer the questions raised by members of the group. As examples only;_


    _a)       The concept of applying FRAND licencing to input data is proving challenging for others to comprehend, more details have been requested, I would like the opportunity to provide them. A lawyer skilled in these principles is now joining the debate and can will likely provide better answers from those seeking to understand the changes than I have been able to._


    _b)      We need a definition of privacy. We agree that the ‘Privacy Principles’ do not provide that. However we still have a gap in the charter. It is important to those that may not have the bandwidth to be involved in every aspect of the possible specifications the group is working on to know the definition of privacy the group will be using._

_If the chairs are not minded to grant this I request they document how they believe they have achieved consensus prior to making the decision to submit the charter._

## Participants Day 1



1. Sean Turner (sn3rd)
2. Aram Zucker-Scharff (The Washington Post)
3. Erik Anderson (Microsoft Edge)
4. Brian May (dstillery)
5. Charlie Harrison (Google Chrome)
6. Eric Rescorla (Mozilla)
7. Don Marti (CafeMedia)
8. Fred Bastello (Index Exchange)
9. Joel Pfeiffer (Microsoft)
10. Wendell Baker (Yahoo)
11. Phillipp Schoppmann (Google)
12. Braedon Vickers
13. Przemyslaw Iwanczak (RTB House)
14. Sean Bedford (Meta)
15. Davis Gilton (Microsoft)
16. Martin Thomson (Mozilla)
17. Alexandre Nderagakura (IAB Europe)
**18. James Rosewell (51Degrees) - left at 1:**38
19. Michael Kleber (Google Chrome)
20. Mariana Raykova (Google)
21. James Aylett (Omnicom / Annalect)
22. Rachit Sharma (IAB Tech Lab)
23. Wendy Seltzer (W3C)
24. Fabian Höring (Criteo)
25. Rotem Dar (eyeo)
26. Ben Savage (Meta)
27. Pedro Alvarado (Resonate)
28. Aloïs Bissuel (Criteo)
29. Richa Jain (Meta)
30. Luke Winstrom (Apple)
31. Alberto Roman (Acuratio)
32. Cornelius Witt (eyeo) 
33. Yoshifumi Takeuchi (Dentsu group)
34. Mariana Raykova (Google)
35. Jonasz Pamula (RTB House)


## Participants Day 2



1. Sean Turner (sn3rd)
2. Aram Zucker-Scharff (The Washington Post)
3. Brian May (dstillery)
4. Braedon Vickers
5. Nick Doty (Center for Democracy & Technology)
6. Erik Anderson (Microsoft Edge)
7. Don Marti (CafeMedia)
8. Michael Kleber (Google Chrome)
9. David Dabbs, Epsilon
10. Rachit Sharma (IAB Tech Lab)
11. Wendy Seltzer (W3C)
12. Martin Thomson (Mozilla)
13. Charlie Harrison (Google Chrome)
14. Joel Pfeiffer (MSFT)
15. Davis Gilton (Microsoft)
16. Alex Cone (IAB Tech Lab)
17. Sean Bedford (Meta)
18. Ben Savage (Meta)
19. Przemyslaw Iwanczak (RTB House)
20. Luke Winstrom (Apple)
21. Fabian Höring (Criteo)
22. Aloïs Bissuel (Criteo)
23. James Aylett (Omnicom / Annalect)
24. Yoshifumi Takeuchi (Dentsu ) - left at 16:49
25. Alexandre Nderagakura (IAB Europe)
26. Alberto Roman (Acuratio)
27. Phillipp Schoppmann (Google)
28. Richa Jain (Meta)
29. Rotem Dar (eyeo)
30. Pedro Alvarado (Resonate) 
31. Jonasz Pamula (RTB House)
